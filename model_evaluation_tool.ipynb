{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b370e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\66891\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import shap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def save_model(model, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def evaluate_models(models_paths, X_test, y_test):\n",
    "    results = []\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for path in models_paths:\n",
    "        name = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        model = load_model(path)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        best_threshold, best_recall = 0.5, 0\n",
    "        thresholds = np.linspace(0.1, 0.9, 81)\n",
    "        for t in thresholds:\n",
    "            y_pred = (y_proba >= t).astype(int)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            if rec > best_recall:\n",
    "                best_recall = rec\n",
    "                best_threshold = t\n",
    "\n",
    "        y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred_best)\n",
    "        recall = recall_score(y_test, y_pred_best)\n",
    "        f1 = f1_score(y_test, y_pred_best)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.2f})\")\n",
    "\n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'threshold': best_threshold,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1,\n",
    "            'auc': auc,\n",
    "            'confusion_matrix': cm,\n",
    "            'model_obj': model,\n",
    "            'y_proba': y_proba\n",
    "        })\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    df_results = pd.DataFrame([{k: v for k, v in r.items() if k not in ['model_obj', 'y_proba', 'confusion_matrix']} for r in results])\n",
    "    display(df_results.sort_values('recall', ascending=False))\n",
    "\n",
    "    for res in results:\n",
    "        print(\"\\n=================\", res['model'], \"=================\")\n",
    "        print(f\"Threshold: {res['threshold']:.2f}, Recall: {res['recall']:.3f}, Precision: {res['precision']:.3f}, F1: {res['f1']:.3f}, AUC: {res['auc']:.3f}\")\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(res['confusion_matrix'])\n",
    "\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(res['model_obj'])\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            shap.summary_plot(shap_values, X_test, show=False)\n",
    "            plt.title(f\"SHAP Summary: {res['model']}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"[!] SHAP not supported for {res['model']}:\", e)\n",
    "\n",
    "    def interactive_threshold(model_result):\n",
    "        def update(thresh):\n",
    "            y_pred = (model_result['y_proba'] >= thresh).astype(int)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"\\nThreshold: {thresh:.2f}\")\n",
    "            print(\"Confusion matrix:\")\n",
    "            print(cm)\n",
    "            print(f\"Recall: {recall:.3f}, Precision: {precision:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "        return widgets.interact(update, thresh=widgets.FloatSlider(min=0.1, max=0.9, step=0.01, value=model_result['threshold']))\n",
    "\n",
    "    print(\"\\n========= Interaktywny próg dla najlepszego modelu =========\")\n",
    "    best_model = max(results, key=lambda x: x['recall'])\n",
    "    interactive_threshold(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1fcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('learning_set.csv')\n",
    "df.head()\n",
    "\n",
    "# Zakładamy, że kolumna celu nazywa się:\n",
    "target_column = 'Lung_Cancer_Diagnosis'\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,        # zachowujemy proporcje klas!\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "evaluate_models(\n",
    "    models_paths=[\n",
    "        \"models/logreg.pkl\",\n",
    "        \"models/xgboost.pkl\",\n",
    "        \"models/lightgbm.pkl\",\n",
    "        \"models/catboost.pkl\"\n",
    "    ],\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
